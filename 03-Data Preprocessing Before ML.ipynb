{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data before machine learning\n",
    "\n",
    "In preparation to the machine learning tutorial/practical, we are going to preprocess the data to get the most out of it.  We are using some ideas proposed in https://www.ahmedbesbes.com/blog/kaggle-titanic-competition  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data using pandas as we learnt in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# we are loading data from github. \n",
    "dataurl = 'https://github.com/rrr-uom-projects/MPiCRT-AI/raw/main/Data/titanic.csv' \n",
    "pax = pd.read_csv(dataurl, sep = ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to understand the data we have to start making sense of it. Here is a short description of the series:\n",
    "\n",
    "- **PassengerId** Arbitrary nr between 1 and 841\n",
    "- **Survived** Weather Survived or not: 0 = No, 1 = Yes\n",
    "- **Pclass** Ticket class: 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- **Name** Name of the Passenger\n",
    "- **Sex** Female/male\n",
    "- **Age** Age in years\n",
    "- **SibSp** No. of siblings / spouses aboard the Titanic\n",
    "- **Parch** No. of parents / children aboard the Titanic\n",
    "- **Ticket** Ticket number\n",
    "- **Fare** Passenger fare\n",
    "- **Cabin** Cabin number\n",
    "- **Embarked** Port of Embarkation:C = Cherbourg, Q = Queenstown, S = Southampton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sort the categorical variables correctly here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax['Sex'] = pax['Sex'].astype('category')\n",
    "pax['Survived'] = pax['Survived'].astype(\"category\")\n",
    "pax['Pclass'] = pax['Pclass'].astype(\"category\")\n",
    "pax['Embarked'] = pax['Embarked'].astype(\"category\")\n",
    "\n",
    "pax.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the data we have is the same as the training dataset of the Kaggle competition: https://www.kaggle.com/c/titanic/  \n",
    "We will learn about training/validation/testing data split on next lecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's import seaborn for visualisation and other useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, the outcome we want to predict is called the **target variable**.  Anything that is used to predict the target is called a **feature**. Many of the algorithms that we will use do not support missing data in the features nor categorical variables, so we will need to do some data transformation to make it compatible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Important variables - Univariable testing with SciPy\n",
    "\n",
    "Let's see if the patterns/differences we observed last time are 'statiscally' solid. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sex? Class? - Categorical Variables\n",
    "\n",
    "In the previous notebook we were able to see some patterns and realised that females were more likely to survive, and that people in the lowest class was less likely to survive.  Let's plot what we mean:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(10, 3)) # plotting multiple panels\n",
    "sns.countplot( x='Sex',hue='Survived', data=pax, stat='percent', ax=axs[0] )\n",
    "sns.countplot( x='Pclass',hue='Survived', data=pax, stat='percent', ax=axs[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also test this to see whether what we see is statistically significances. In this case, we want to test whether two categorical variables are related, e.g., Sex vs Survived or Pclass vs Survived.  The common test used in this situation is the Chi-squared test. \n",
    "\n",
    "Let's use the implementation in SciPy: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2_contingency.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use this test, we need to build a contingency table.  In this table we simply summarise the number of times all combinations of the categorical values are observed.  Let's do this:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_suriv_contingency_table = pd.crosstab(pax[\"Sex\"], pax[\"Survived\"])\n",
    "print(sex_suriv_contingency_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2, p, dof, expected = chi2_contingency(sex_suriv_contingency_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the number of categories, the expected contigency table if there was no relationship between these variables is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Expected frequencies:\")\n",
    "print(pd.DataFrame(expected, index=sex_suriv_contingency_table.index, columns=sex_suriv_contingency_table.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the p-value will tell us whether the differences we are seeing are significant or not. \n",
    "\n",
    "Given a level of significance (often 0.05) we can check whether the differences we see are due to chance:\n",
    "- If p < 0.05, we reject the null hypothesis. In this case, we will say that there is likely a relationship between Sex and Survival. \n",
    "- If p > 0.05 then we say that the difference is not significant and it can be attributed to chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"P-value: {p}\")\n",
    "print(f\"Is it significant at 0.05? {p<0.05}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the value is super small, so we can say that the difference in survival between males/females is very unlikely to be caused by chance.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can run a similar analysis for Pclass:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_suriv_contingency_table = pd.crosstab(pax[\"Pclass\"], pax[\"Survived\"])\n",
    "print(pclass_suriv_contingency_table)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(pclass_suriv_contingency_table)\n",
    "\n",
    "print(\"Expected frequencies:\")\n",
    "print(pd.DataFrame(expected, index=pclass_suriv_contingency_table.index, columns=pclass_suriv_contingency_table.columns))\n",
    "\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Is it significant at 0.05? {p<0.05}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the p-value, what can you conclude?\n",
    "\n",
    "You can also repeat this analysis with Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write some code here?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age? Fare? - Continous variable\n",
    "\n",
    "We also saw a different pattern related on the Age and Fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(8, 3)) # plotting multiple panels\n",
    "sns.violinplot(y='Age', hue='Survived', data=pax,  split=True, ax=axs[0] )\n",
    "sns.violinplot(y='Fare', hue='Survived', data=pax,  split=True, ax=axs[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test this difference using, for example, the t-test: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agesurv0 = pax.loc[pax['Survived']==0,'Age']\n",
    "agesurv1 = pax.loc[pax['Survived']==1,'Age']\n",
    "print(np.mean(agesurv0), np.mean(agesurv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat,p=ttest_ind(agesurv0,agesurv1)\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why did we get nan??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### count values that are nan here:\n",
    "\n",
    "# what do they mean? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A way around this is to tell scipy to ignore nan values when running the ttest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstat,p=ttest_ind(agesurv0,agesurv1,nan_policy='omit')\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Is it significant at a 0.05 level? {p<0.05}\")\n",
    "print(f\"Is it significant at a 0.01 level? {p<0.01}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting the p-value... What is your conclusion? (assuming a level of significance of 0.05)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the analysis for Fare.  We already know that Fare is correlated to Pclass, so the question is whether with find a similar correlation with Survived.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(4, 3)) # plotting multiple panels\n",
    "sns.boxplot(x='Pclass',y='Fare',data=pax, ax=axs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "faresurv0 = pax.loc[pax['Survived']==0,'Fare']\n",
    "faresurv1 = pax.loc[pax['Survived']==1,'Fare']\n",
    "print(np.mean(faresurv0), np.mean(faresurv1))\n",
    "tstat,p=ttest_ind(faresurv0,faresurv1,nan_policy='omit')\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could argue that Fare is not normally distributed. Alternatively, you could use Mann Withney U test: https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.mannwhitneyu.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "print(np.median(faresurv0), np.median(faresurv1))\n",
    "stat,p=mannwhitneyu(faresurv0,faresurv1,nan_policy='omit')\n",
    "print(f\"P-value: {p}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can you conclude? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with missing values\n",
    "\n",
    "We already saw that having NaN values can make our life difficult.  This is why it is important to decide what to do about missing data.  \n",
    "\n",
    "One approach is to 'drop' all the entries with missing values. That can be done with the function dropna: https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html\n",
    "\n",
    "Let's see what this would do to our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paxnonans = pax.dropna()\n",
    "print('Before dropping NaNs:', pax.shape)\n",
    "print('After dropping NaNs: ', paxnonans.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we are left with ~20% of the data (183 rather than 891 passangers).  This will heavily limit our ability to do any machine learning on this data!  Instead, let's first figure out which are the values that have more missing values and whether it is worth working on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order: \n",
    "- Cabin has >77% missing values. Is this an important variable??\n",
    "- Age has almost 20% missing values. Is this an important variable? \n",
    "- Embarked has 2 missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputing Age\n",
    "\n",
    "We need to see whether there are differences for Age related to other features, e.g. Sex, Pclass, Embarked, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,3,figsize=(10, 3)) # plotting multiple panels\n",
    "sns.boxplot(x='Pclass',y='Age',data=pax, ax=axs[0] )\n",
    "sns.violinplot(hue='Sex',y='Age',data=pax, split=True,ax=axs[1] )\n",
    "sns.boxenplot(x='Embarked',y='Age',data=pax, ax=axs[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianAges = pax.groupby(['Sex','Pclass','Embarked'], observed=True)[['Age']].median()\n",
    "medianAges = medianAges.reset_index()\n",
    "print(medianAges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create a function tht given a line with missing values, returns the median according to their Sex, Pclass and Embarkment point:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMedianAgeForCategory(row):\n",
    "    # using the dataframe medianAges created above.\n",
    "    condition = (\n",
    "        (medianAges['Sex'] == row['Sex']) & \n",
    "        (medianAges['Pclass'] == row['Pclass']) & \n",
    "        (medianAges['Embarked'] == row['Embarked'])\n",
    "    ) \n",
    "    return medianAges[condition]['Age'].values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find one passenger with Age == NaN and see it applied:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pax.loc[np.isnan(pax['Age']),['Pclass','Sex','Embarked','Age']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index  = 19\n",
    "row =  pax.loc[index,['Pclass','Sex','Embarked','Age']]\n",
    "print(row)\n",
    "print('>> Imputed age: ', getMedianAgeForCategory(row))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now impute for all values that are missing in the Series Age, using the function Apply(): https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imputeIfNeeded(row):\n",
    "    return getMedianAgeForCategory(row) if np.isnan(row['Age']) else row['Age']\n",
    "\n",
    "# Alternatively:\n",
    "#def imputeIfNeeded(row):\n",
    "#    theage = row['Age']\n",
    "#    if np.isnan(theage):\n",
    "#        theage = getMedianAgeForCategory(row)\n",
    "#    return theage\n",
    "\n",
    "\n",
    "#let's make a copy of the values before imputing\n",
    "pax['AgeWithoutNaNs'] = pax.apply(imputeIfNeeded, axis=1)\n",
    "pax.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's check that we have not messed up the values that were there before.\n",
    "sns.scatterplot(x='Age',y='AgeWithoutNaNs',data=pax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding extra information\n",
    "\n",
    "Up to now we have not done much with the variable Name (beside counting Mary's in the first notebook!) nor SibSp/Parch. We could still extract some information from these.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Titles?\n",
    "If we observe this variable, each name has the title of the person:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax['Name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some domain information, we can see that these titles can give us extra information. For example, if there was any person from the Royal family, it is likely they would survive independent of the Sex, Fare, Embarkment, etc.  \n",
    "\n",
    "Let' try and extract these data.  We see that the title is always after a comma and finishes in a dot. We have already extracted the surname in the first notebook, let's copy the relevant code and extend it here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to cast the type of the Name series to str. \n",
    "pax['Name'] = pax['Name'].astype('string')\n",
    "surnamefirstnames = pax['Name'].str.split(',')  # this splits the string by the token given (,)\n",
    "pax['Surname'] = surnamefirstnames.str.get(0)   # here we get the first bit of the divided sentence\n",
    "afterComma = surnamefirstnames.str.get(1).str.split('.')# this splits the string by the token given (.)\n",
    "pax['Title'] = afterComma.str.get(0).str.strip()        # here we get the first bit of the divided sentence and eliminate empty spaces\n",
    "print(pax['Title'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With some knowledge of titles (and checking the blog), we see that these titles correspond to crew/officers of the ship, Royalty, etc..\n",
    "\n",
    "- Capt: Officer,\n",
    "- Col: Officer,\n",
    "- Major: Officer,\n",
    "- Jonkheer: Royalty,\n",
    "- Don: Royalty,\n",
    "- Sir : Royalty,\n",
    "- Dr: Officer,\n",
    "- Rev: Officer,\n",
    "- the Countess:Royalty,\n",
    "- Mme: Mrs,\n",
    "- Mlle: Miss,\n",
    "- Ms: Mrs,\n",
    "- Mr : Mr,\n",
    "- Mrs : Mrs,\n",
    "- Miss : Miss,\n",
    "- Master : Master,\n",
    "- Lady : Royalty\n",
    "\n",
    "We can use a similar strategy as you used in a previous practical to create a new category: TitleType.  For this we can create a dictionary and use map()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Title_Dictionary = {\n",
    "    \"Capt\": \"Officer\",\n",
    "    \"Col\": \"Officer\",\n",
    "    \"Major\": \"Officer\",\n",
    "    \"Jonkheer\": \"Royalty\",\n",
    "    \"Don\": \"Royalty\",\n",
    "    \"Sir\" : \"Royalty\",\n",
    "    \"Dr\": \"Officer\",\n",
    "    \"Rev\": \"Officer\",\n",
    "    \"the Countess\":\"Royalty\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royalty\"\n",
    "}\n",
    "pax['TitleType'] = pax['Title'].map(Title_Dictionary)\n",
    "pax['TitleType'] = pax['TitleType'].astype('category')\n",
    "print(pax['TitleType'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=(4, 3)) # plotting multiple panels\n",
    "sns.countplot( x='TitleType',hue='Survived', data=pax, stat='percent', ax=axs )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is it significant?  If so, is it confounded?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_suriv_contingency_table = pd.crosstab(pax[\"TitleType\"], pax[\"Survived\"])\n",
    "print(title_suriv_contingency_table)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(title_suriv_contingency_table)\n",
    "\n",
    "print(\"Expected frequencies:\")\n",
    "print(pd.DataFrame(expected, index=title_suriv_contingency_table.index, columns=title_suriv_contingency_table.columns))\n",
    "\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Is it significant at 0.05? {p<0.05}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family sizes?\n",
    "\n",
    "We have also ignored up to now the variables SibSp (nr of Siblings/Spouses) and Parch (nr of parents/children) related to a given passanger.  We could assume that as large families are grouped together, then they are more likely to get rescued than people traveling/floating alone.\n",
    "\n",
    "We can then create a variable 'family size' and binary variables identifying whether the passanger was travelling on their own, or as part of a small or larger family."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "pax['FamilySize'] = pax['SibSp']+pax['Parch']+1 # why +1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getFamilyType(famsize):\n",
    "    return 'single' if famsize == 1 else ('smallFamily' if famsize < 5 else 'largeFamily')\n",
    "\n",
    "pax['FamilyType'] = pax['FamilySize'].apply(getFamilyType)\n",
    "pax['FamilyType'] = pax['FamilyType'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1,2,figsize=(10, 3)) # plotting multiple panels\n",
    "sns.countplot( x='FamilySize',hue='Survived', data=pax, stat='percent', ax=axs[0] )\n",
    "sns.countplot( x='FamilyType',hue='Survived', data=pax, stat='percent', ax=axs[1] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was the assumption of larger families more likely to survive supported by the data?  You could also do some testing here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "famtype_suriv_contingency_table = pd.crosstab(pax[\"FamilyType\"], pax[\"Survived\"])\n",
    "print(famtype_suriv_contingency_table)\n",
    "\n",
    "chi2, p, dof, expected = chi2_contingency(famtype_suriv_contingency_table)\n",
    "\n",
    "print(\"Expected frequencies:\")\n",
    "print(pd.DataFrame(expected, index=famtype_suriv_contingency_table.index, columns=famtype_suriv_contingency_table.columns))\n",
    "\n",
    "print(f\"P-value: {p}\")\n",
    "print(f\"Is it significant at 0.05? {p<0.05}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Variables\n",
    "\n",
    "Some of the approaches we will test later on do not work good with categories. So, we need to create 'dummy' variables, where the content are just True/False depending on the value of the category.  For example the variable FamilyType would create 3 dummy variables: FamilyType_single, FamilyType_smallFamily and FamilyType_LargeFamily.  \n",
    "\n",
    "The function 'get_dummies' from pandas would do that for us:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_dummies = pd.get_dummies(pax['FamilyType'], prefix='FamilyType')\n",
    "print(family_dummies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do this to all important categorical variables in the dataset for the classification practical next week."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
