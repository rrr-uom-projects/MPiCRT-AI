{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xJWBwCEOkjvL"
   },
   "source": [
    "# Classification using Convolutional Neural Networks\n",
    "\n",
    "We will now train our a convolutional neural network (CNN) classifier using PyTorch.  We will use the MNIST dataset for this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3745,
     "status": "ok",
     "timestamp": 1741845182927,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "qSreD2vMoHTP"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNwnYQfsABNf"
   },
   "source": [
    "For running this tutorial in colab, please be sure your runtime has a GPU. For this, go to [Runtime] then click [Change runtime type] and be sure you have any of the GPUs selected.  \n",
    "\n",
    "If all this works, the next code cell should print *cuda*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1741845182963,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "FjtgaqtksoeV",
    "outputId": "8395353c-fef7-4171-d188-9150b5cd95c4"
   },
   "outputs": [],
   "source": [
    "# Define the device (CPU or GPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_ysfPSHmmW0K"
   },
   "source": [
    "## MNIST dataset\n",
    "The MNIST dataset is a collection of *60.000* training images and *10.000* test images of handwritten digits (0–9), each in a 28x28 pixel grayscale format.\n",
    "\n",
    "It was introduced in:\n",
    "LeCun, Y., Bottou, L., Bengio, Y., & Haffner, P. (1998). Gradient-based learning applied to document recognition. Proceedings of the IEEE, 86(11), 2278–2324. https://doi.org/10.1109/5.726791\n",
    "\n",
    "This dataset is often used to learn how CNNs work, and to compare classification models. PyTorch has included it in its datasets.  Other datasets can be found here:\n",
    "https://pytorch.org/vision/main/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1741845182991,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "Yiskz2lql46s"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "# Define the dataset and transformations\n",
    "train_dataset = MNIST(root=\"data\", train=True, download=True, transform=ToTensor())\n",
    "test_dataset = MNIST(root=\"data\", train=False, download=True, transform=ToTensor())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XD-qC0yEqNCF"
   },
   "source": [
    "Let's visualise some images from the training dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 675
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1741845183509,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "Xe5_qjlJqMbh",
    "outputId": "bb650c92-f10d-4137-e3bc-4708f7bbc7f9"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "cols, rows = 3, 3\n",
    "for i in range(1, cols * rows + 1):\n",
    "    sample_idx = torch.randint(len(train_dataset), size=(1,)).item()\n",
    "    img, label = train_dataset[sample_idx]\n",
    "    figure.add_subplot(rows, cols, i)\n",
    "    plt.title(label)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-5IuWG4k_hz"
   },
   "source": [
    "## DataLoader\n",
    "PyTorch has implemented a class called *DataLoader* to use mini-batch optimisation. We will use it for training our classifier.\n",
    "\n",
    "You can find more info here:\n",
    "- https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader\n",
    "- https://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6jF8cI3Oudjh"
   },
   "source": [
    "We will first divide our training set into train/validation.  We will use 'random_split' from PyTorch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 50,
     "status": "ok",
     "timestamp": 1741845183560,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "aGHVT_tlkNbS"
   },
   "outputs": [],
   "source": [
    "train, validation = torch.utils.data.random_split(train_dataset, [0.8, 0.2], generator=torch.Generator().manual_seed(1234))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V6NQ-95euq3e"
   },
   "source": [
    "And now we use DataLoader with a given batch file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741845183578,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "8OlvkX0YuqGx"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validationloader = torch.utils.data.DataLoader(validation, batch_size=batch_size, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q1N4Uc7wvP6U"
   },
   "source": [
    "## Definining the CNN\n",
    "We will implement a simple CNN with two Convolutional layers, and two fully connected layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 115,
     "status": "ok",
     "timestamp": 1741845183694,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "GD7Vizpiwcnz"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class OurCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3) # 32 kernels in this layer\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3) # 64 kernels in this layer\n",
    "        self.fc1 = nn.Linear(64, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)  # 10: 10 labels 0-9\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        # Use adaptive pooling instead of maxpooling\n",
    "        x = nn.functional.adaptive_avg_pool2d(x, (1, 1))\n",
    "        # Flatten the tensor before passing it to the fully connected layers\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return nn.functional.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KVIL3sSx1K1"
   },
   "source": [
    "We can now create the model. The model is an object of the class OurCNN, and we need to assign the device we are working with (this time it should be cuda)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1741845183708,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "Or0saNSfx6rS",
    "outputId": "9b43402d-a212-45f0-dc6c-1b32a7b8a067"
   },
   "outputs": [],
   "source": [
    "amodel = OurCNN().to(device)\n",
    "print(amodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jW9n8_cHyBwD"
   },
   "source": [
    "## Training the neural network\n",
    "\n",
    "Remember that training is optimising the values of the trainable parameters using some hyperparameters to define the model characteristics and guide the optimisation process.  Here we have already decided on the model characteristics when we defined OurCNN.  The next part is how to set up the training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIoCbzVgy7Wq"
   },
   "source": [
    "### Training 1 epoch\n",
    "\n",
    "We need to write what to do when the model is train for one epoch (that is, when the optimiser sees the complete dataset and updates the parameters).  In this case, we want to compute the average error (loss function) across all backpropagation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1741845183710,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "n2HkPBIazHsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def train_1epoch(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    sumloss = 0\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # accumulate the loss for this epoch\n",
    "        sumloss += loss.item()\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), (batch + 1) * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "    return sumloss / num_batches\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNy-zbOm0UyY"
   },
   "source": [
    "### Evaluating without changing parameters\n",
    "We should also check the model's performance against the validation dataset to be sure it is learning and assess wether it is underfiting, overfitting, or doing just right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1741845183727,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "gsOPTAHL0acW"
   },
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Validation Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6crYHUN81nM6"
   },
   "source": [
    "### Training loop\n",
    "\n",
    "Finally, we need to make the trainable loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 31,
     "status": "ok",
     "timestamp": 1741845183759,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "47sMTHOB1sFi"
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def train_loop(traindataloader,valdataloader,model,epochs):\n",
    "  optimiser = optim.Adam(model.parameters(), lr=1e-3)\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  trainloss = []\n",
    "  validationloss = []\n",
    "  valaccuracies = []\n",
    "  for t in range(epochs):\n",
    "      print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "      tl = train_1epoch(traindataloader, model, loss_fn, optimiser)\n",
    "      vl, va = test(valdataloader, model, loss_fn)\n",
    "      print(f\"Epoch {t+1}\\tLosses:  Training {tl}, Validation {vl}.\" )\n",
    "      trainloss.append(tl)\n",
    "      validationloss.append(vl)\n",
    "      valaccuracies.append(va)\n",
    "  print(\"Training done!\")\n",
    "  return trainloss, validationloss, valaccuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 83893,
     "status": "ok",
     "timestamp": 1741845267637,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "4go5m0dH10kl",
    "outputId": "ad650a06-d5e1-43e9-cba0-3516858b4683"
   },
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "ourmodel = OurCNN().to(device)\n",
    "trainloss, validationloss, valaccuracies = train_loop(trainloader,validationloader,ourmodel,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxgB2N8i2yt3"
   },
   "source": [
    "### Plotting learning curves\n",
    "Let's try and identify if we trained the best possible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 388
    },
    "executionInfo": {
     "elapsed": 363,
     "status": "ok",
     "timestamp": 1741845268003,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "BvDjy6r822vd",
    "outputId": "85b41926-5506-4e86-b2f3-b3cbf2c27d72"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=(4, 4)) # plotting multiple panels: 1 row, 2 columns\n",
    "axs.plot(trainloss,'b-',label=\"Training Loss\")\n",
    "axs.plot(validationloss,'b:', label=\"Validation Loss\")\n",
    "\n",
    "axs.set_xlabel(\"Epochs\")\n",
    "axs.set_ylabel(\"Loss\")\n",
    "axs.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lQNx8XVk3xg6"
   },
   "source": [
    "What do these curves tell you? 🤔"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rdfzIwB1roc"
   },
   "source": [
    "## Implementing K-fold cross validation\n",
    "\n",
    "PyTorch does not include an implementation of KFold within their dataloaders.  Instead, we can use KFold from SKLearn to help us, as proposed [here](https://saturncloud.io/blog/how-to-use-kfold-cross-validation-with-dataloaders-in-pytorch/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199622,
     "status": "ok",
     "timestamp": 1741845467627,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "_tV43OTC3qlF",
    "outputId": "82efc730-6691-48b6-c51f-a209c3657e58"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Define the number of folds and batch size\n",
    "k_folds = 5\n",
    "\n",
    "# Initialize the k-fold cross validation\n",
    "kf = KFold(n_splits=k_folds, shuffle=True)\n",
    "\n",
    "foldtrainingloss = []\n",
    "foldvalidationloss = []\n",
    "foldvalidationaccuracy = []\n",
    "# Loop through each fold\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dataset)):\n",
    "    print(f\"Fold {fold + 1}\")\n",
    "    print(\"-------\")\n",
    "\n",
    "    # Define the data loaders for the current fold\n",
    "    foldtrainloader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size,sampler=torch.utils.data.SubsetRandomSampler(train_idx))\n",
    "    foldvalidationloader = torch.utils.data.DataLoader(dataset=train_dataset,batch_size=batch_size,sampler=torch.utils.data.SubsetRandomSampler(val_idx))\n",
    "\n",
    "    # Initialize the model\n",
    "    foldmodel = OurCNN().to(device)\n",
    "\n",
    "    # run it for few epochs to make it during class\n",
    "    epochs = 5\n",
    "    foldtl, foldvl, foldva = train_loop(foldtrainloader,foldvalidationloader,foldmodel,epochs)\n",
    "\n",
    "    # keep the losses to plot them\n",
    "    foldtrainingloss.append(foldtl)\n",
    "    foldvalidationloss.append(foldvl)\n",
    "    foldvalidationaccuracy.append(foldva)\n",
    "print('Done!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P8VU4r8J4JTC"
   },
   "source": [
    "Let's plot these now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 678,
     "status": "ok",
     "timestamp": 1741845468315,
     "user": {
      "displayName": "Eliana Vásquez Osorio",
      "userId": "05097373148219502702"
     },
     "user_tz": 0
    },
    "id": "YLnRKr2P886B",
    "outputId": "f1959fb1-fbf9-41fc-d75f-ae027b7e7e57"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "\n",
    "fig, axs = plt.subplots(k_folds,1,figsize=(4,4*k_folds)) # plotting multiple panels: k_fold rows\n",
    "for foldi in range(k_folds):\n",
    "  axs[foldi].plot(foldtrainingloss[foldi],'b-',label=\"Training Loss\")\n",
    "  axs[foldi].plot(foldvalidationloss[foldi],'b:', label=\"Validation Loss\")\n",
    "\n",
    "  axs[foldi].set_xlabel(\"Epochs\")\n",
    "  axs[foldi].set_ylabel(\"Loss\")\n",
    "  axs[foldi].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnbzG4aZ-ZM4"
   },
   "source": [
    "\n",
    "# Final thoughts\n",
    "\n",
    "There are many resources to learn more about CNNs using PyTorch.  \n",
    "I recommend you to look in the PyTorch tutorials for some help:\n",
    "- https://pytorch.org/tutorials/beginner/basics/intro.html\n",
    "- https://pytorch.org/tutorials/\n",
    "- https://pytorch.org/vision/main/models.html to explore transfer learning.\n",
    "\n",
    "Small tips related to the final project:\n",
    "- When you are happy with one of the models, you should save the weights.  For this, use torch.save.  Check this tutorial for that: https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html\n",
    "- You can think of creating your own DataSet (or DataLoader) for including biases in training. Check https://pytorch.org/tutorials/beginner/basics/data_tutorial.html or play with the sampler as we did here for the K-fold.\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNXL5x6ngnJEvf2iR+Du9ds",
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
